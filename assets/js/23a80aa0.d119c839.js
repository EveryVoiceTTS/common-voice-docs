"use strict";(self.webpackChunkcommon_voice_docs=self.webpackChunkcommon_voice_docs||[]).push([[35],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return m}});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var d=a.createContext({}),s=function(e){var t=a.useContext(d),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=s(e.components);return a.createElement(d.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,d=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),c=s(n),m=o,g=c["".concat(d,".").concat(m)]||c[m]||u[m]||r;return n?a.createElement(g,i(i({ref:t},p),{},{components:n})):a.createElement(g,i({ref:t},p))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=c;var l={};for(var d in t)hasOwnProperty.call(t,d)&&(l[d]=t[d]);l.originalType=e,l.mdxType="string"==typeof e?e:o,i[1]=l;for(var s=2;s<r;s++)i[s]=n[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},4627:function(e,t,n){n.r(t),n.d(t,{assets:function(){return p},contentTitle:function(){return d},default:function(){return m},frontMatter:function(){return l},metadata:function(){return s},toc:function(){return u}});var a=n(7462),o=n(3366),r=(n(7294),n(3905)),i=["components"],l={},d="Changing the Audio Format",s={unversionedId:"audio",id:"audio",title:"Changing the Audio Format",description:"To change the audio codec, the format & the sample rate, you have to add the following lines to .env-local-docker which is located at the root of the repository.",source:"@site/docs/audio.md",sourceDirName:".",slug:"/audio",permalink:"/common-voice-docs/docs/audio",editUrl:"https://github.com/joanise/common-voice-docs/tree/main/docs/audio.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Amazon",permalink:"/common-voice-docs/docs/amazon"},next:{title:"Auth0",permalink:"/common-voice-docs/docs/auth0"}},p={},u=[{value:"Available Lossless Audio Codecs",id:"available-lossless-audio-codecs",level:2},{value:"Available Formats",id:"available-formats",level:2},{value:"S3 File Name",id:"s3-file-name",level:2},{value:"Default Sample Rate?",id:"default-sample-rate",level:2},{value:"Common Voice&#39;s AudioWeb Class",id:"common-voices-audioweb-class",level:2},{value:"Resources",id:"resources",level:2},{value:"How Common Voice Sets up the Audio Analyzer",id:"how-common-voice-sets-up-the-audio-analyzer",level:2},{value:"Figuring out the Hacky Way",id:"figuring-out-the-hacky-way",level:2},{value:"Payload Type",id:"payload-type",level:2},{value:"Payload",id:"payload",level:2},{value:"Script that Lists Supported Codecs",id:"script-that-lists-supported-codecs",level:2},{value:"Brave",id:"brave",level:2}],c={toc:u};function m(e){var t=e.components,n=(0,o.Z)(e,i);return(0,r.kt)("wrapper",(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"changing-the-audio-format"},"Changing the Audio Format"),(0,r.kt)("p",null,"To change the audio codec, the format & the sample rate, you have to add the following lines to ",(0,r.kt)("inlineCode",{parentName:"p"},".env-local-docker")," which is located at the root of the repository."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"CV_TRANSCODE_CODEC='pcm_s16le'\nCV_TRANSCODE_FORMAT='wav'\nCV_TRANSCODE_SAMPLE_RATE='44100'\n")),(0,r.kt)("p",null,"or"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"CV_TRANSCODE_CODEC='pcm_s24le'\nCV_TRANSCODE_FORMAT='wav'\nCV_TRANSCODE_SAMPLE_RATE='96000'\n")),(0,r.kt)("h2",{id:"available-lossless-audio-codecs"},"Available Lossless Audio Codecs"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'ffmpeg -codecs |& grep ".EA..S"\n')),(0,r.kt)("p",null,"or"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'docker container exec -it web ffmpeg -codecs |& grep ".EA..S"\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker container exec -it web ffmpeg -codecs \\\n |& grep \".EA..S\" \\\n | sed -e 's| \\([^ ]\\+\\) \\([^ ]\\+\\) \\+\\(.\\+\\)|\\1\\t\\2\\t\\3|' \\\n | tabulate --sep $'\\t' --format pipe\n")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Attributes"),(0,r.kt)("th",{parentName:"tr",align:null},"Name"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"alac"),(0,r.kt)("td",{parentName:"tr",align:null},"ALAC (Apple Lossless Audio Codec)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA.LS"),(0,r.kt)("td",{parentName:"tr",align:null},"dts"),(0,r.kt)("td",{parentName:"tr",align:null},"DCA (DTS Coherent Acoustics) (decoders: dca ) (encoders: dca )")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"flac"),(0,r.kt)("td",{parentName:"tr",align:null},"FLAC (Free Lossless Audio Codec)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"mlp"),(0,r.kt)("td",{parentName:"tr",align:null},"MLP (Meridian Lossless Packing)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_f32be"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM 32-bit floating point big-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_f32le"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM 32-bit floating point little-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_f64be"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM 64-bit floating point big-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_f64le"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM 64-bit floating point little-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s16be"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 16-bit big-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s16be_planar"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 16-bit big-endian planar")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s16le"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 16-bit little-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s16le_planar"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 16-bit little-endian planar")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s24be"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 24-bit big-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s24daud"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM D-Cinema audio signed 24-bit")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s24le"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 24-bit little-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s24le_planar"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 24-bit little-endian planar")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s32be"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 32-bit big-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s32le"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 32-bit little-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s32le_planar"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 32-bit little-endian planar")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s64be"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 64-bit big-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s64le"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 64-bit little-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s8"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 8-bit")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_s8_planar"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM signed 8-bit planar")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_u16be"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM unsigned 16-bit big-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_u16le"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM unsigned 16-bit little-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_u24be"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM unsigned 24-bit big-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_u24le"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM unsigned 24-bit little-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_u32be"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM unsigned 32-bit big-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_u32le"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM unsigned 32-bit little-endian")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"pcm_u8"),(0,r.kt)("td",{parentName:"tr",align:null},"PCM unsigned 8-bit")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"s302m"),(0,r.kt)("td",{parentName:"tr",align:null},"SMPTE 302M")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"truehd"),(0,r.kt)("td",{parentName:"tr",align:null},"TrueHD")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA..S"),(0,r.kt)("td",{parentName:"tr",align:null},"tta"),(0,r.kt)("td",{parentName:"tr",align:null},"TTA (True Audio)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"DEA.LS"),(0,r.kt)("td",{parentName:"tr",align:null},"wavpack"),(0,r.kt)("td",{parentName:"tr",align:null},"WavPack (encoders: wavpack libwavpack )")))),(0,r.kt)("h2",{id:"available-formats"},"Available Formats"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"ffmpeg -formats\n")),(0,r.kt)("p",null,"or"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker container exec -it web ffmpeg -formats\n")),(0,r.kt)("h2",{id:"s3-file-name"},"S3 File Name"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"server/src/lib/clip.ts"),":",(0,r.kt)("inlineCode",{parentName:"p"},"saveClip()"),"\nSaving the audio content on S3."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},"   const { client_id, headers } = request;\n   const sentenceId = headers.sentence_id as string;\n\n   const folder = client_id + '/';\n   const filePrefix = sentenceId;\n   const clipFileName = folder + filePrefix + '.' + config.TRANSCODE.FORMAT;\n\n   await this.s3\n     .upload({\n       Bucket: config.CLIP_BUCKET_NAME,\n       Key: clipFileName,\n       Body: audioOutput,\n     })\n     .promise();\n")),(0,r.kt)("p",null,"I think utterances are identified by a ",(0,r.kt)("inlineCode",{parentName:"p"},"client_id + sentenceId"),".\nThe recording are saved in a bucket and there metadata in a database.\n",(0,r.kt)("inlineCode",{parentName:"p"},"this.model.db.clipExists(client_id, sentenceId)")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},"    await this.model.saveClip({\n      client_id: client_id,\n      localeId: sentence.locale_id,\n      original_sentence_id: sentenceId,\n      path: clipFileName,\n      sentence: sentence.text,\n    });\n")),(0,r.kt)("h1",{id:"audio-recording-in-the-browser"},"Audio Recording in the Browser"),(0,r.kt)("p",null,"What audio format/bit/sample rate is recorded by the browser?"),(0,r.kt)("h2",{id:"default-sample-rate"},"Default Sample Rate?"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/AudioContext"},"https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/AudioContext")),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"sampleRate")," Optional"),(0,r.kt)("p",null,"Indicates the sample rate to use for the new context.\nThe value must be a floating-point value indicating the sample rate, in samples per second, for which to configure the new context; additionally, the value must be one which is supported by AudioBuffer.sampleRate.\nThe value will typically be between 8,000 Hz and 96,000 Hz; the default will vary depending on the output device, but the sample rate 44,100 Hz is the most common.\n",(0,r.kt)("strong",{parentName:"p"},"If the sampleRate property is not included in the options, or the options are not specified when creating the audio context, the new context's output device's preferred sample rate is used by default.")),(0,r.kt)("h2",{id:"common-voices-audioweb-class"},"Common Voice's AudioWeb Class"),(0,r.kt)("p",null,"Common-Voice web UI has a AudioWeb object:\nweb/src/components/pages/contribution/speak/audio-web.ts"),(0,r.kt)("h2",{id:"resources"},"Resources"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://developer.mozilla.org/en-US/docs/Web/API/MediaStream"},"MediaStream")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/MediaRecorder"},"MediaRecorder")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://developer.mozilla.org/en-US/docs/Web/API/AudioContext"},"AudioContext")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/AudioContext"},"AudioContext::AudioContext()"))),(0,r.kt)("h2",{id:"how-common-voice-sets-up-the-audio-analyzer"},"How Common Voice Sets up the Audio Analyzer"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"web/src/components/pages/contribution/speak/audio-web.ts")),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"AudioWeb::init()")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-ts"},"// Set up the analyzer node, and allocate an array for its data\n// FFT size 64 gives us 32 bins. But those bins hold frequencies up to\n// 22kHz or more, and we only care about lower frequencies which is where\n// most human voice lies, so we use fewer bins.\nanalyzerNode.fftSize = 128;\nanalyzerNode.smoothingTimeConstant = 0.96;\nthis.frequencyBins = new Uint8Array(analyzerNode.frequencyBinCount);\n")),(0,r.kt)("h2",{id:"figuring-out-the-hacky-way"},"Figuring out the Hacky Way"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-diff"},"diff --git a/web/src/components/pages/contribution/speak/speak.tsx b/web/src/components/pages/contribution/speak/speak.tsx\nindex 4d023c1cf..3a9357bcc 100755\n--- a/web/src/components/pages/contribution/speak/speak.tsx\n+++ b/web/src/components/pages/contribution/speak/speak.tsx\n@@ -360,6 +360,7 @@ class SpeakPage extends React.Component<Props, State> {\n\n   private startRecording = async () => {\n     try {\n+      console.log(`startRecording: ${JSON.stringify(this.audio)}`);\n       await this.audio.start();\n       this.maxVolume = -1; // Initialize to -1 in case updateVolume is never called.\n       this.recordingStartTime = Date.now();\n")),(0,r.kt)("p",null,"Start recording an utterance then look into your browser's log console."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"AudioContext {baseLatency: 0.01, outputLatency: 0, destination: AudioDestinationNode, currentTime: 0, sampleRate: 48000, \u2026}\naudioWorklet: AudioWorklet {}\nbaseLatency: 0.01\ncurrentTime: 6.84\ndestination: AudioDestinationNode\nchannelCount: 2\nchannelCountMode: \"explicit\"\nchannelInterpretation: \"speakers\"\ncontext: AudioContext\naudioWorklet: AudioWorklet {}\nbaseLatency: 0.01\ncurrentTime: 82.06933333333333\ndestination: AudioDestinationNode {maxChannelCount: 2, context: AudioContext, numberOfInputs: 1, numberOfOutputs: 0, channelCount: 2, \u2026}\nlistener: AudioListener {positionX: AudioParam, positionY: AudioParam, positionZ: AudioParam, forwardX: AudioParam, forwardY: AudioParam, \u2026}\nonstatechange: null\noutputLatency: 0.053\nsampleRate: 48000\nstate: \"running\"\n[[Prototype]]: AudioContext\nmaxChannelCount: 2\nnumberOfInputs: 1\nnumberOfOutputs: 0\n[[Prototype]]: AudioDestinationNode\nlistener: AudioListener\nforwardX: AudioParam {value: 0, automationRate: 'a-rate', defaultValue: 0, minValue: -3.4028234663852886e+38, maxValue: 3.4028234663852886e+38}\nforwardY: AudioParam {value: 0, automationRate: 'a-rate', defaultValue: 0, minValue: -3.4028234663852886e+38, maxValue: 3.4028234663852886e+38}\nforwardZ: AudioParam {value: -1, automationRate: 'a-rate', defaultValue: -1, minValue: -3.4028234663852886e+38, maxValue: 3.4028234663852886e+38}\npositionX: AudioParam {value: 0, automationRate: 'a-rate', defaultValue: 0, minValue: -3.4028234663852886e+38, maxValue: 3.4028234663852886e+38}\npositionY: AudioParam {value: 0, automationRate: 'a-rate', defaultValue: 0, minValue: -3.4028234663852886e+38, maxValue: 3.4028234663852886e+38}\npositionZ: AudioParam {value: 0, automationRate: 'a-rate', defaultValue: 0, minValue: -3.4028234663852886e+38, maxValue: 3.4028234663852886e+38}\nupX: AudioParam {value: 0, automationRate: 'a-rate', defaultValue: 0, minValue: -3.4028234663852886e+38, maxValue: 3.4028234663852886e+38}\nupY: AudioParam {value: 1, automationRate: 'a-rate', defaultValue: 1, minValue: -3.4028234663852886e+38, maxValue: 3.4028234663852886e+38}\nupZ: AudioParam {value: 0, automationRate: 'a-rate', defaultValue: 0, minValue: -3.4028234663852886e+38, maxValue: 3.4028234663852886e+38}\n[[Prototype]]: AudioListener\nonstatechange: null\noutputLatency: 0.053\nsampleRate: 48000\nstate: \"running\"\n[[Prototype]]: AudioContext\n")),(0,r.kt)("h2",{id:"payload-type"},"Payload Type"),(0,r.kt)("p",null,"Capturing traffic between the browser and the server using the build-in developer tools in Brave, we can see that the payload sent to ",(0,r.kt)("inlineCode",{parentName:"p"},"http://localhost:9000/api/v1/git/clips")," contains the string ",(0,r.kt)("inlineCode",{parentName:"p"},"OPUS")," which suggests that the audio format used during transfer is OPUS."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"E\xdf\xa3BB\xf7B\xf2B\xf3\bBwebmBBSg\xff\xff\xff\xff\xff\xff\xffI\xa9f*\xd7\xb1B@MChromeWAChromeT\xaek\xbf\xae\xbd\xd7s\xc5\xdd\xa1\"\xb80\xa1A_OPUSc\xa2OpusHead\xbb\xe1\xb5G;bd C\xb6u\xff\xff\xff\xff\xff\xff\xff\xe7\xa3A0{8_\xe4\xc16\xf8E]\xeaQ%\xd5\xb3\xddD\xfaE\xc1zC\\\xd9\xafp'@\xa4_\xc8\xd8\xd0\xccR:\xaekv03\xef<\xb8y\xd0KM\xe5\xdbw\xdd \xd9j\xd3e/`\xff\xf25P\xaaR0\xc0\xf8x\xf9\xdd\xd7A?_^\xe65!*\xd3D\xdcc0\xc1@\xd0\xa7_\xed\xe3\xf7\xdc\\#,v\xb3:X\xe8\xe5r6\xd7v\xf5:\xadXn\n")),(0,r.kt)("h1",{id:"getting-96khz24-bits"},"Getting 96kHZ@24 bits"),(0,r.kt)("p",null,"From what I understand, the sample rate is specified when creating the ",(0,r.kt)("inlineCode",{parentName:"p"},"AudioContext"),".\nBut the bit depth is specified when creating the ",(0,r.kt)("inlineCode",{parentName:"p"},"MediaRecorder"),".\nBoth are handled in the AudioWeb under ",(0,r.kt)("inlineCode",{parentName:"p"},"web/src/components/pages/contribution/speak/audio-web.ts"),".\nAnother required change is to make sure the browser's audio buffer is in raw mode.\nUnder ",(0,r.kt)("inlineCode",{parentName:"p"},"web/src/utility.ts"),"::",(0,r.kt)("inlineCode",{parentName:"p"},"getAudioFormat()"),", we determine the audio buffer internal encoding to be ",(0,r.kt)("inlineCode",{parentName:"p"},"audio/ogg; codecs=opus")," by default.\nLet's change the default to be ",(0,r.kt)("inlineCode",{parentName:"p"},"audio/wav"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-diff"},"diff --git a/web/src/components/pages/contribution/speak/audio-web.ts b/web/src/components/pages/contribution/speak/audio-web.ts\nindex 7a6a5cd4b..8931abcf3 100644\n--- a/web/src/components/pages/contribution/speak/audio-web.ts\n+++ b/web/src/components/pages/contribution/speak/audio-web.ts\n@@ -112,7 +116,7 @@ export default class AudioWeb {\n    * the page is reloaded if the user decides to do so.\n    *\n    */\n-  async init() {\n+  async init(sampleRate: number=96000) {\n     if (this.isReady()) {\n       return;\n     }\n@@ -121,7 +125,7 @@ export default class AudioWeb {\n\n     this.microphone = microphone;\n     const audioContext = new (window.AudioContext ||\n-      window.webkitAudioContext)();\n+      window.webkitAudioContext)({sampleRate: sampleRate});\n     const sourceNode = audioContext.createMediaStreamSource(microphone);\n     const volumeNode = audioContext.createGain();\n     const analyzerNode = audioContext.createAnalyser();\n@@ -139,7 +143,12 @@ export default class AudioWeb {\n     analyzerNode.connect(outputNode);\n\n     // and set up the recorder.\n-    this.recorder = new window.MediaRecorder(outputNode.stream);\n+    this.recorder = new window.MediaRecorder(\n+      outputNode.stream,\n+      {\n+        mimeType: \"audio/webm;codecs=PCM\",\n+      },\n+    );\n\n     // Set up the analyzer node, and allocate an array for its data\n     // FFT size 64 gives us 32 bins. But those bins hold frequencies up to\ndiff --git a/web/src/utility.ts b/web/src/utility.ts\nindex a8e0cfd5c..dccc8480a 100644\n--- a/web/src/utility.ts\n+++ b/web/src/utility.ts\n@@ -90,7 +90,8 @@ export function getManageSubscriptionURL(account: UserClient) {\n }\n\n export const getAudioFormat = (() => {\n-  const preferredFormat = 'audio/ogg; codecs=opus';\n+  //const preferredFormat = 'audio/ogg; codecs=opus';\n+  const preferredFormat = \"audio/wav\";\n   const audio = document.createElement('audio');\n   const format = audio.canPlayType(preferredFormat)\n     ? preferredFormat\n")),(0,r.kt)("h2",{id:"payload"},"Payload"),(0,r.kt)("p",null,"The client now sends a playload that seems to be PCM."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"I\xa9f\x99*\xd7\xb1\x83s\xc5\x876\xc54I\xa9f\x99*\xd7\xb1\x83\n\x96\n~\x83\x81\x02\x86\x90A_PCM/FLOAT/IEEE\xe1\x8d\xb5\x84G\xbb\x80\x9f\x81\x96bd\x81 \x1fC\xb6u\x96\xff\xff\xff\xff\xff\xff\xff\xe7\x81\xa3O\x81\x80\xa3O\x80D\xe2\x962^V@1I\x84 @\xb0\xb2L\xe1:2\n")),(0,r.kt)("h1",{id:"investigation-notes"},"Investigation Notes"),(0,r.kt)("p",null,"Where is the default audio format hardcoded."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"~/git/Common-Voice/web/src/utility.ts")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"export const getAudioFormat = (() => {\n  const preferredFormat = 'audio/ogg; codecs=opus';\n  const audio = document.createElement('audio');\n  const format = audio.canPlayType(preferredFormat)\n    ? preferredFormat\n    : 'audio/wav';\n  return function getAudioFormat() {\n    return format;\n  };\n})();\n")),(0,r.kt)("p",null,"This is where we create the audio blob which is encoded according to ",(0,r.kt)("inlineCode",{parentName:"p"},"getAudioFormat()"),"."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"~/git/Common-Voice/web/src/components/pages/contribution/speak/audio-web.ts")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"  stop(): Promise<AudioInfo> {\n      if (!this.isReady()) {\n        console.error('Cannot stop audio before microphone is ready.');\n        return Promise.reject();\n      }\n\n      return new Promise((res: Function, rej: Function) => {j\n        this.jsNode.onaudioprocess = undefined;\n        this.recorder.removeEventListener('stop', this.recorderListeners.stop);\n        this.recorderListeners.stop = (e: Event) => {\n          let blob = new Blob(this.chunks, { type: getAudioFormat() });\n          res({\n            url: URL.createObjectURL(blob),\n            blob: blob,\n          });\n        };\n        this.recorder.addEventListener('stop', this.recorderListeners.stop);\n        this.recorder.stop();\n      });\n    }\n")),(0,r.kt)("p",null,"I think we are better off not asking for a specific sample rate when Transcoding because we might try to upscale the sample rate."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"server/src/lib/clip.ts")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"      const audioOutput = new Transcoder(audioInput)\n        .audioCodec(config.TRANSCODE.AUDIO_CODEC)\n        .format(config.TRANSCODE.FORMAT)\n        .channels(1)\n        .sampleRate(config.TRANSCODE.SAMPLE_RATE)\n        //.sampleRate(config.TRANSCODE.SAMPLE_RATE)\n        .on('error', (error: string) => {\n          this.clipSaveError(\n            headers,\n")),(0,r.kt)("h1",{id:"supported-codecs-in-browser"},"Supported Codecs in Browser"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/ai/audio-recorder-polyfill"},"Audio Formats")),(0,r.kt)("p",null,"Chrome records natively only to .webm files. Firefox to .ogg."),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/awslabs/aws-lex-browser-audio-capture/blob/master/lib/worker.js"},"manually encoding to wav")),(0,r.kt)("h2",{id:"script-that-lists-supported-codecs"},"Script that Lists Supported Codecs"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'<!DOCTYPE html>\n<html lang="en-US">\n  <head>\n    <meta charset="UTF-8" />\n    <title>createMediaStreamDestination() demo</title>\n  </head>\n  <body>\n    <h1>createMediaStreamDestination() demo</h1>\n\n    <p>Encoding a pure sine wave to an Opus file</p>\n    <button>Make sine wave</button>\n    <audio controls></audio>\n    <div id="codecs"></div>\n\n    <script>\n       //const mimeType = "audio/ogg; codecs=opus";\n       const mimeType = "audio/wav";\n       //const mimeType = "audio/pcm;rate=96000";\n       //const mimeType = "audio/x-ogg-pcm";\n       //const mimeType = "audio/x-ogg-flac";\n       //const mimeType = "audio/webm;codecs=PCM";\n\n      const b = document.querySelector("button");\n      let clicked = false;\n      const chunks = [];\n      const ac = new AudioContext({sampleRate: 96000});\n      const osc = ac.createOscillator();\n      const dest = ac.createMediaStreamDestination();\n      const mediaRecorder = new MediaRecorder(\n         dest.stream,\n         {\n            mimeType: "audio/webm;codecs=PCM",\n         },\n      );\n      osc.connect(dest);\n\n      b.addEventListener("click", (e) => {\n        if (!clicked) {\n          mediaRecorder.start();\n          osc.start(0);\n          e.target.textContent = "Stop recording";\n          clicked = true;\n        } else {\n          mediaRecorder.stop();\n          osc.stop(0);\n          e.target.disabled = true;\n        }\n      });\n\n      mediaRecorder.ondataavailable = (evt) => {\n        // Push each chunk (blobs) in an array\n        console.log(evt.data.type);\n        chunks.push(evt.data);\n      };\n\n      mediaRecorder.onstop = (evt) => {\n         // https://www.digipres.org/formats/mime-types/\n        // Make blob out of our blobs, and open it.\n        const blob = new Blob(chunks, { type: mimeType});\n        document.querySelector("audio").src = URL.createObjectURL(blob);\n      };\n    <\/script>\n\n\n    <script>\n      // https://stackoverflow.com/questions/41739837/all-mime-types-supported-by-mediarecorder-in-firefox-and-chrome/42307926#42307926\n      function getSupportedMimeTypes(media, types, codecs) {\n        const isSupported = MediaRecorder.isTypeSupported;\n        const supported = [];\n        types.forEach((type) => {\n          const mimeType = `${media}/${type}`;\n          codecs.forEach((codec) => [\n            `${mimeType};codecs=${codec}`,\n            `${mimeType};codecs=${codec.toUpperCase()}`,\n            // /!\\ false positive /!\\\n            // `${mimeType};codecs:${codec}`,\n            // `${mimeType};codecs:${codec.toUpperCase()}` \n          ].forEach(variation => {\n            if(isSupported(variation)) \n              supported.push(variation);\n          }));\n          if (isSupported(mimeType))\n            supported.push(mimeType);\n        });\n        return supported;\n      };\n\n      function displayCodecs(codecs, type) {\n        const el = document.getElementById("codecs");\n\n        let node = document.createElement("div");\n        el.appendChild(node);\n\n        title = document.createElement("H1");\n        title.setHTML(type);\n        node.appendChild(title);\n\n        codecs.forEach((codec, id) => {\n          const p = document.createElement("p");\n          p.setHTML(codec);\n          if (id === 0) {\n            p.setAttribute("style", "color:red");\n          }\n          node.appendChild(p);\n        });\n      }\n\n      // Usage ------------------\n\n      const videoTypes = ["webm", "ogg", "mp4", "x-matroska"];\n      const audioTypes = ["webm", "ogg", "mp3", "x-matroska"];\n      const codecs = ["should-not-be-supported","vp9", "vp9.0", "vp8", "vp8.0", "avc1", "av1", "h265", "h.265", "h264", "h.264", "opus", "pcm", "aac", "mpeg", "mp4a"];\n\n      const supportedVideos = getSupportedMimeTypes("video", videoTypes, codecs);\n      const supportedAudios = getSupportedMimeTypes("audio", audioTypes, codecs);\n\n      displayCodecs(supportedAudios, "Audio");\n      displayCodecs(supportedVideos, "Video");\n    <\/script>\n  </body>\n</html>\n')),(0,r.kt)("h2",{id:"brave"},"Brave"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"-- Top supported Audio :  audio/webm;codecs=opus\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'-- All supported Audios :\n0 : "audio/webm;codecs=opus"\n1 : "audio/webm;codecs=OPUS"\n2 : "audio/webm;codecs=pcm"\n3 : "audio/webm;codecs=PCM"\n4 : "audio/webm"\n')))}m.isMDXComponent=!0}}]);